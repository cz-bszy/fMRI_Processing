#!/bin/bash

set -euo pipefail

# =============================================================================
# Script: FC_step6
# Description:
#   Enhanced results extraction script that:
#   1. Extracts preprocessed fMRI data
#   2. Organizes results into NoGRS and GRS folders
#   3. Supports both single-subject and batch processing
# =============================================================================

# ---------------------------- Configuration ----------------------------------

INPUT_DIR=""
OUTPUT_DIR=""
FSF_TYPE=""
LOG_DIR=""
SKIP_EXISTING=false
DRY_RUN=false
VERBOSE=false

# ---------------------------- Usage Function --------------------------------

usage() {
    echo "Enhanced Results Extraction Script"
    echo "Usage: $0 [options]" >&2
    echo ""
    echo "Required Arguments:"
    echo "  -i    Input data directory"
    echo "  -o    Output directory"
    echo "  -f    FSF type (NoGRS or GRS)"
    echo ""
    echo "Optional Arguments:"
    echo "  -l    Log directory (default: output_dir/logs)"
    echo "  -x    Skip existing processed subjects"
    echo "  -d    Dry run (show commands without executing)"
    echo "  -v    Verbose output"
    echo "  -h    Display this help message"
    exit 1
}

# ---------------------------- Functions -------------------------------------

log() {
    local level="$1"
    shift
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] [$level] $*" >&2
    if [ ! -z "$LOG_DIR" ]; then
        echo "[$(date +'%Y-%m-%d %H:%M:%S')] [$level] $*" >> "$LOG_DIR/extract_$(date +'%Y%m%d').log"
    fi
}

validate_input() {
    if [ -z "$INPUT_DIR" ] || [ -z "$OUTPUT_DIR" ] || [ -z "$FSF_TYPE" ]; then
        log "ERROR" "Input directory, output directory, and FSF type must be specified."
        usage
    fi

    if ! [[ "$FSF_TYPE" =~ ^(NoGRS|GRS)$ ]]; then
        log "ERROR" "FSF type must be either NoGRS or GRS"
        exit 1
    fi

    if [ ! -d "$INPUT_DIR" ]; then
        log "ERROR" "Input directory '$INPUT_DIR' does not exist."
        exit 1
    fi
}

process_subject() {
    local subject_id="$1"
    local session="$2"
    
    # Source directory (from processed data)
    local processed_dir="${OUTPUT_DIR}/${subject_id}"
    [ ! -z "$session" ] && [ "$session" != "\"\"" ] && processed_dir="${processed_dir}/${session}"
    
    local source_file="${processed_dir}/func/rest_res2standard.nii.gz"
    
    # Modified target directory and filename
    local target_dir="${OUTPUT_DIR}/results"
    mkdir -p "$target_dir"
    
    # Create target filename based on presence of session
    local target_filename
    if [ -z "$session" ] || [ "$session" = "\"\"" ]; then
        target_filename="${subject_id}_${FSF_TYPE}.nii.gz"
    else
        target_filename="${subject_id}_${session}_${FSF_TYPE}.nii.gz"
    fi
    
    local target_file="${target_dir}/${target_filename}"
    
    if [ ! -f "$source_file" ]; then
        log "ERROR" "Source file not found: $source_file"
        return 1
    fi
    
    if [ "$SKIP_EXISTING" = true ] && [ -f "$target_file" ]; then
        log "INFO" "Results already exist for $target_filename. Skipping."
        return 0
    fi
    
    if [ "$DRY_RUN" = true ]; then
        log "DRY-RUN" "Would copy $source_file to $target_file"
        return 0
    fi
    
    if ! cp "$source_file" "$target_file"; then
        log "ERROR" "Failed to copy file for $target_filename"
        return 1
    fi
    
    log "SUCCESS" "Extracted results as $target_filename"
    return 0
}

# ---------------------------- Main Script ----------------------------------

# Process command line arguments
while getopts "i:o:f:l:xdvh" opt; do
    case ${opt} in
        i) INPUT_DIR="$OPTARG";;
        o) OUTPUT_DIR="$OPTARG";;
        f) FSF_TYPE="$OPTARG";;
        l) LOG_DIR="$OPTARG";;
        x) SKIP_EXISTING=true;;
        d) DRY_RUN=true;;
        v) VERBOSE=true;;
        h) usage;;
        \?) log "ERROR" "Invalid Option: -$OPTARG"; usage;;
        :) log "ERROR" "Option -$OPTARG requires an argument."; usage;;
    esac
done


validate_input


if [ -z "$LOG_DIR" ]; then
    LOG_DIR="$OUTPUT_DIR/logs"
fi
mkdir -p "$LOG_DIR"

# Create temporary file for subject list
temp_file=$(mktemp)
trap 'rm -f "$temp_file"' EXIT

# Find subjects and sessions
log "INFO" "Scanning input directory for subjects..."
while IFS= read -r dir; do
    subject_dir=$(basename "$dir")
    
    if [[ -d "$dir/func" ]]; then
        echo "$subject_dir \"\"" >> "$temp_file"
    else
        while IFS= read -r session_dir; do
            session=$(basename "$session_dir")
            if [[ -d "$session_dir/func" ]]; then
                echo "$subject_dir $session" >> "$temp_file"
            fi
        done < <(find "$dir" -mindepth 1 -maxdepth 1 -type d)
    fi
done < <(find "$INPUT_DIR" -mindepth 1 -maxdepth 1 -type d)

total_subjects=$(wc -l < "$temp_file")
log "INFO" "Found $total_subjects subject/session combinations to process"

if [ "$total_subjects" -eq 0 ]; then
    log "ERROR" "No subjects found in input directory"
    exit 1
fi

if [ "$DRY_RUN" = true ]; then
    log "DRY-RUN" "Would process the following subjects:"
    cat "$temp_file"
    exit 0
fi

# Process subjects
export -f process_subject
export -f log
export INPUT_DIR OUTPUT_DIR FSF_TYPE LOG_DIR SKIP_EXISTING DRY_RUN VERBOSE

parallel --progress --colsep ' ' \
    process_subject {1} {2} < "$temp_file"

log "SUCCESS" "All results extracted successfully"